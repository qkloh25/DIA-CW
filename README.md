
# Demo Video
https://youtu.be/53Z-DgA-s6s

# Folder structure
 ```
ğŸ“¦DIA CW
 â”£ ğŸ“‚tmp             # To save the weight of the neural network
 â”ƒ â”£ ğŸ“‚DQN_agent_centralised
 â”ƒ â”ƒ â”£ ğŸ“œpolicy
 â”ƒ â”ƒ â”— ğŸ“œtarget
 â”ƒ â”£ ğŸ“‚DQN_agent_distributed_1
 â”ƒ â”ƒ â”£ ğŸ“œpolicy
 â”ƒ â”ƒ â”— ğŸ“œtarget
 â”ƒ â”£ ğŸ“‚DQN_agent_distributed_2
 â”ƒ â”ƒ â”£ ğŸ“œpolicy
 â”ƒ â”ƒ â”— ğŸ“œtarget
 â”ƒ â”£ ğŸ“‚MAA2C_agent_1
 â”ƒ â”— ğŸ“‚MAA2C_agent_2
 â”£ ğŸ“œagents.py
 â”£ ğŸ“œbuffers.py
 â”£ ğŸ“œcsettings.py
 â”£ ğŸ“œDQN_centralised_evaluate      #Evaluation score for 1-DQN
 â”£ ğŸ“œDQN_centralised_train_score   #Train score for 1-DQN
 â”£ ğŸ“œDQN_centralised_train_score1  #Train score for 1-DQN(more)
 â”£ ğŸ“œDQN_distributed_evaluate      #Evaluation score for 2-DQN
 â”£ ğŸ“œDQN_distributed_train_score   #Train score for 2-DQN
 â”£ ğŸ“œDQN_distributed_train_score1  #Train score for 1-DQN(more)
 â”£ ğŸ“œenviroments.py
 â”£ ğŸ“œevaluate_centralised.py    # Evaluate the 1DQN 
 â”£ ğŸ“œevaluate_distributed.py    # Evaluate the 2DQN
 â”£ ğŸ“œnetworks.py
 â”£ ğŸ“œplot_evaluate.py       # Plot the evaluation score
 â”£ ğŸ“œplot_training.py       # Plot the training score
 â”£ ğŸ“œREADME.md
 â”£ ğŸ“œtrain_DQN_centralised.py   # Train the 1DQN
 â”£ ğŸ“œtrain_DQN_distributed.py   # Train the 2DQN
 â”— ğŸ“œtrain_MAA2C.py
 ```

 The files to visualise the results would be evaluate_centralised.py and evaluate_distributed.py. If you dont want to see the game running, set render = False.